#![allow(missing_docs)]
//! Cancel Lane Fairness & Starvation Bounds (bd-1jxe3).
//!
//! Proves and tests starvation bounds for cancel-lane prioritization.
//! The three-lane scheduler guarantees that ready/timed tasks are dispatched
//! within `cancel_streak_limit` consecutive cancel dispatches.
//!
//! Key invariant: if ready or timed work is pending, it will be dispatched
//! after at most `cancel_streak_limit` consecutive cancel-lane dispatches.
//!
//! Cross-references:
//!   Scheduler:      src/runtime/scheduler/three_lane.rs
//!   Priority queue: src/runtime/scheduler/priority.rs
//!   Existing tests: tests/scheduler_lane_fairness.rs

use asupersync::runtime::scheduler::three_lane::ThreeLaneScheduler;
use asupersync::runtime::RuntimeState;
use asupersync::test_utils::init_test_logging;
use asupersync::time::{TimerDriverHandle, VirtualClock};
use asupersync::types::{Budget, TaskId, Time};
use std::sync::atomic::{AtomicUsize, Ordering};
use std::sync::{Arc, Mutex};
use std::time::Duration;

// ---------------------------------------------------------------------------
// Helpers
// ---------------------------------------------------------------------------

fn setup_state() -> Arc<Mutex<RuntimeState>> {
    Arc::new(Mutex::new(RuntimeState::new()))
}

fn setup_state_with_clock() -> (Arc<Mutex<RuntimeState>>, Arc<VirtualClock>) {
    let clock = Arc::new(VirtualClock::starting_at(Time::from_nanos(1_000)));
    let mut rs = RuntimeState::new();
    rs.set_timer_driver(TimerDriverHandle::with_virtual_clock(clock.clone()));
    (Arc::new(Mutex::new(rs)), clock)
}

fn create_task(state: &Arc<Mutex<RuntimeState>>, region: asupersync::types::RegionId) -> TaskId {
    let mut guard = state.lock().unwrap();
    let (id, _) = guard
        .create_task(region, Budget::INFINITE, async {})
        .unwrap();
    id
}

fn create_counting_task(
    state: &Arc<Mutex<RuntimeState>>,
    region: asupersync::types::RegionId,
    counter: Arc<AtomicUsize>,
    position_store: Option<Arc<AtomicUsize>>,
) -> TaskId {
    let mut guard = state.lock().unwrap();
    let (id, _) = guard
        .create_task(region, Budget::INFINITE, async move {
            let pos = counter.fetch_add(1, Ordering::SeqCst) + 1;
            if let Some(store) = position_store {
                store.store(pos, Ordering::SeqCst);
            }
        })
        .unwrap();
    id
}

// ===========================================================================
// EXACT BOUND VERIFICATION: PARAMETRIC CANCEL_STREAK_LIMIT
// ===========================================================================

/// Verify the starvation bound holds for a given cancel_streak_limit.
///
/// Proof sketch: With N >> limit cancel tasks and 1 ready task, the ready task
/// must be dispatched at position <= limit + 1 (cancel positions 1..=limit,
/// then fairness yield forces ready at position limit+1).
fn verify_bound_for_limit(cancel_streak_limit: usize) {
    let state = setup_state();
    let region = state.lock().unwrap().create_root_region(Budget::INFINITE);
    let seq = Arc::new(AtomicUsize::new(0));
    let ready_pos = Arc::new(AtomicUsize::new(usize::MAX));

    let mut scheduler = ThreeLaneScheduler::new_with_cancel_limit(1, &state, cancel_streak_limit);

    // Flood cancel lane with 4x the limit.
    let num_cancel = cancel_streak_limit * 4;
    for _ in 0..num_cancel {
        let id = create_counting_task(&state, region, Arc::clone(&seq), None);
        scheduler.inject_cancel(id, 100);
    }

    // One ready task that records its dispatch position.
    let ready_id = create_counting_task(
        &state,
        region,
        Arc::clone(&seq),
        Some(Arc::clone(&ready_pos)),
    );
    scheduler.inject_ready(ready_id, 100);

    // Run worker.
    let workers = scheduler.take_workers();
    let mut worker = workers.into_iter().next().unwrap();
    let handle = std::thread::spawn(move || {
        worker.run_loop();
    });

    std::thread::sleep(Duration::from_millis(300));
    scheduler.shutdown();
    handle.join().unwrap();

    let pos = ready_pos.load(Ordering::SeqCst);
    assert!(
        pos != usize::MAX,
        "ready task never executed (limit={cancel_streak_limit})"
    );
    let bound = cancel_streak_limit + 1;
    assert!(
        pos <= bound,
        "ready task at position {pos} exceeds bound {bound} (limit={cancel_streak_limit})"
    );
}

#[test]
fn bound_cancel_streak_limit_1() {
    init_test_logging();
    verify_bound_for_limit(1);
}

#[test]
fn bound_cancel_streak_limit_2() {
    init_test_logging();
    verify_bound_for_limit(2);
}

#[test]
fn bound_cancel_streak_limit_4() {
    init_test_logging();
    verify_bound_for_limit(4);
}

#[test]
fn bound_cancel_streak_limit_8() {
    init_test_logging();
    verify_bound_for_limit(8);
}

#[test]
fn bound_cancel_streak_limit_16() {
    init_test_logging();
    verify_bound_for_limit(16);
}

#[test]
fn bound_cancel_streak_limit_32() {
    init_test_logging();
    verify_bound_for_limit(32);
}

// ===========================================================================
// PREEMPTION METRICS VALIDATION
// ===========================================================================

#[test]
fn metrics_max_cancel_streak_respects_limit() {
    init_test_logging();
    let state = setup_state();
    let cancel_limit = 4usize;
    let mut scheduler = ThreeLaneScheduler::new_with_cancel_limit(1, &state, cancel_limit);

    // Inject many cancel tasks and one ready task.
    let num_cancel = cancel_limit * 5;
    for i in 0..num_cancel {
        scheduler.inject_cancel(TaskId::new_for_test(1, i as u32), 10);
    }
    scheduler.inject_ready(TaskId::new_for_test(2, 0), 10);

    let mut workers = scheduler.take_workers().into_iter();
    let mut worker = workers.next().expect("worker");

    // Dispatch all tasks by calling next_task until empty.
    let mut dispatched = 0;
    while worker.next_task().is_some() {
        dispatched += 1;
        if dispatched > num_cancel + 10 {
            break; // Safety valve
        }
    }

    let metrics = worker.preemption_metrics();
    let max_streak = metrics.max_cancel_streak;
    assert!(
        max_streak <= cancel_limit,
        "max_cancel_streak ({max_streak}) should be <= cancel_streak_limit ({cancel_limit})"
    );
    assert!(
        metrics.fairness_yields > 0,
        "should have yielded at least once with {num_cancel} cancel tasks"
    );
    assert_eq!(
        metrics.ready_dispatches, 1,
        "exactly one ready task should dispatch"
    );
    assert_eq!(
        metrics.cancel_dispatches as usize, num_cancel,
        "all cancel tasks should dispatch"
    );
}

#[test]
fn metrics_no_fairness_yield_when_cancel_below_limit() {
    init_test_logging();
    let state = setup_state();
    let cancel_limit = 16usize;
    let mut scheduler = ThreeLaneScheduler::new_with_cancel_limit(1, &state, cancel_limit);

    // Inject fewer cancel tasks than the limit.
    let num_cancel = cancel_limit / 2;
    for i in 0..num_cancel {
        scheduler.inject_cancel(TaskId::new_for_test(1, i as u32), 10);
    }
    scheduler.inject_ready(TaskId::new_for_test(2, 0), 10);

    let mut workers = scheduler.take_workers().into_iter();
    let mut worker = workers.next().expect("worker");

    let mut count = 0;
    while worker.next_task().is_some() {
        count += 1;
        if count > num_cancel + 5 {
            break;
        }
    }

    let metrics = worker.preemption_metrics();
    assert_eq!(
        metrics.fairness_yields, 0,
        "no fairness yield needed when cancel count < limit"
    );
}

// ===========================================================================
// TIMED LANE STARVATION BOUND
// ===========================================================================

#[test]
fn timed_task_dispatches_within_bound() {
    init_test_logging();
    let (state, _clock) = setup_state_with_clock();
    let region = state.lock().unwrap().create_root_region(Budget::INFINITE);
    let seq = Arc::new(AtomicUsize::new(0));
    let timed_pos = Arc::new(AtomicUsize::new(usize::MAX));

    let cancel_limit = 4usize;
    let mut scheduler = ThreeLaneScheduler::new_with_cancel_limit(1, &state, cancel_limit);

    // Flood cancel lane.
    let num_cancel = cancel_limit * 3;
    for _ in 0..num_cancel {
        let id = create_counting_task(&state, region, Arc::clone(&seq), None);
        scheduler.inject_cancel(id, 100);
    }

    // One timed task (already due).
    let timed_id = create_counting_task(
        &state,
        region,
        Arc::clone(&seq),
        Some(Arc::clone(&timed_pos)),
    );
    scheduler.inject_timed(timed_id, Time::ZERO);

    let workers = scheduler.take_workers();
    let mut worker = workers.into_iter().next().unwrap();
    let handle = std::thread::spawn(move || {
        worker.run_loop();
    });

    std::thread::sleep(Duration::from_millis(300));
    scheduler.shutdown();
    handle.join().unwrap();

    let pos = timed_pos.load(Ordering::SeqCst);
    assert!(pos != usize::MAX, "timed task never executed");
    let bound = cancel_limit + 1;
    assert!(
        pos <= bound,
        "timed task at position {pos} exceeds bound {bound} (limit={cancel_limit})"
    );
}

// ===========================================================================
// STREAK RESET BEHAVIOR
// ===========================================================================

#[test]
fn streak_resets_after_ready_dispatch() {
    init_test_logging();
    let state = setup_state();
    let cancel_limit = 3usize;
    let mut scheduler = ThreeLaneScheduler::new_with_cancel_limit(1, &state, cancel_limit);

    // Phase 1: cancel_limit cancels + 1 ready (forces yield, streak resets).
    for i in 0..cancel_limit {
        scheduler.inject_cancel(TaskId::new_for_test(1, i as u32), 10);
    }
    scheduler.inject_ready(TaskId::new_for_test(2, 0), 10);

    // Phase 2: another batch of cancel_limit cancels + 1 ready.
    for i in 0..cancel_limit {
        scheduler.inject_cancel(TaskId::new_for_test(3, i as u32), 10);
    }
    scheduler.inject_ready(TaskId::new_for_test(4, 0), 10);

    let mut workers = scheduler.take_workers().into_iter();
    let mut worker = workers.next().expect("worker");

    let mut dispatch_order = Vec::new();
    let total = (cancel_limit * 2) + 2;
    for _ in 0..total + 5 {
        match worker.next_task() {
            Some(id) => dispatch_order.push(id),
            None => break,
        }
    }

    // Verify the ready tasks appear at most cancel_limit positions apart.
    let ready_positions: Vec<usize> = dispatch_order
        .iter()
        .enumerate()
        .filter(|(_, id)| **id == TaskId::new_for_test(2, 0) || **id == TaskId::new_for_test(4, 0))
        .map(|(i, _)| i)
        .collect();

    assert_eq!(
        ready_positions.len(),
        2,
        "both ready tasks should dispatch: got {ready_positions:?}"
    );

    // Each ready task should appear within cancel_limit+1 of its batch start.
    for pos in &ready_positions {
        assert!(
            *pos <= cancel_limit + (cancel_limit + 1), // Worst case: limit batch 1 + limit batch 2 + 1
            "ready at position {pos} too late"
        );
    }
}

// ===========================================================================
// FALLBACK CANCEL DISPATCH (CANCEL-ONLY WORKLOAD)
// ===========================================================================

#[test]
fn fallback_cancel_when_no_other_work() {
    init_test_logging();
    let state = setup_state();
    let cancel_limit = 2usize;
    let mut scheduler = ThreeLaneScheduler::new_with_cancel_limit(1, &state, cancel_limit);

    // Only cancel tasks â€” no ready or timed.
    let num_cancel = cancel_limit * 3;
    for i in 0..num_cancel {
        scheduler.inject_cancel(TaskId::new_for_test(1, i as u32), 10);
    }

    let mut workers = scheduler.take_workers().into_iter();
    let mut worker = workers.next().expect("worker");

    let mut count = 0;
    while worker.next_task().is_some() {
        count += 1;
        if count > num_cancel + 5 {
            break;
        }
    }

    // All cancel tasks should eventually dispatch (fallback allows it).
    assert_eq!(
        count, num_cancel,
        "all {num_cancel} cancel tasks should dispatch via fallback"
    );

    let metrics = worker.preemption_metrics();
    assert!(
        metrics.fallback_cancel_dispatches > 0,
        "fallback cancel dispatches should be > 0 when no other work"
    );
}

// ===========================================================================
// FIFO ORDERING WITHIN CANCEL LANE
// ===========================================================================

#[test]
fn cancel_lane_dispatches_fifo() {
    init_test_logging();
    let state = setup_state();
    let mut scheduler = ThreeLaneScheduler::new(1, &state);

    // Cancel queue is a SegQueue (FIFO), so injection order determines
    // dispatch order regardless of the priority tag.
    let first_in = TaskId::new_for_test(1, 0);
    let second_in = TaskId::new_for_test(1, 1);
    let third_in = TaskId::new_for_test(1, 2);

    scheduler.inject_cancel(first_in, 1);
    scheduler.inject_cancel(second_in, 50);
    scheduler.inject_cancel(third_in, 100);

    let mut workers = scheduler.take_workers().into_iter();
    let mut worker = workers.next().expect("worker");

    let first = worker.next_task().expect("first");
    let second = worker.next_task().expect("second");
    let third = worker.next_task().expect("third");

    // FIFO: injection order preserved.
    assert_eq!(
        first, first_in,
        "first injected cancel should dispatch first"
    );
    assert_eq!(
        second, second_in,
        "second injected cancel should dispatch second"
    );
    assert_eq!(
        third, third_in,
        "third injected cancel should dispatch third"
    );
}

// ===========================================================================
// CONTINUOUS INJECTION STRESS
// ===========================================================================

#[test]
fn continuous_cancel_injection_does_not_starve_ready() {
    init_test_logging();
    let state = setup_state();
    let region = state.lock().unwrap().create_root_region(Budget::INFINITE);

    let cancel_limit = 8usize;
    let mut scheduler = ThreeLaneScheduler::new_with_cancel_limit(1, &state, cancel_limit);

    // Create ready task.
    let ready_id = create_task(&state, region);
    scheduler.inject_ready(ready_id, 100);

    // Pre-inject cancel tasks.
    let initial_cancel = cancel_limit * 2;
    for _ in 0..initial_cancel {
        let id = create_task(&state, region);
        scheduler.inject_cancel(id, 100);
    }

    // Run worker and continuously inject more cancel tasks from another thread.
    let workers = scheduler.take_workers();
    let mut worker = workers.into_iter().next().unwrap();

    let state_clone = Arc::clone(&state);
    let scheduler_ref = &scheduler;

    // Spawn injector thread.
    let injector_done = Arc::new(std::sync::atomic::AtomicBool::new(false));
    let injector_done_clone = Arc::clone(&injector_done);
    let inject_handle = {
        let state = Arc::clone(&state_clone);
        std::thread::spawn(move || {
            for _ in 0..100 {
                if injector_done_clone.load(Ordering::Acquire) {
                    break;
                }
                let id = {
                    let mut guard = state.lock().unwrap();
                    let (id, _) = guard
                        .create_task(region, Budget::INFINITE, async {})
                        .unwrap();
                    id
                };
                // Can't inject from another thread after take_workers; skip.
                // The pre-injected batch is sufficient to test.
                let _ = id;
                std::thread::sleep(Duration::from_millis(1));
            }
        })
    };

    let worker_handle = std::thread::spawn(move || {
        worker.run_loop();
    });

    // Wait for ready task to complete.
    let start = std::time::Instant::now();
    let timeout = Duration::from_secs(3);
    let mut completed = false;
    while start.elapsed() < timeout {
        if state.lock().unwrap().task(ready_id).is_none() {
            completed = true;
            break;
        }
        std::thread::sleep(Duration::from_millis(10));
    }

    injector_done.store(true, Ordering::Release);
    scheduler_ref.shutdown();
    worker_handle.join().unwrap();
    inject_handle.join().unwrap();

    assert!(
        completed,
        "ready task starved by continuous cancel injection"
    );
}

// ===========================================================================
// MULTI-WORKER FAIRNESS BOUND
// ===========================================================================

#[test]
fn multi_worker_all_lanes_complete_within_bound() {
    init_test_logging();
    let (state, _clock) = setup_state_with_clock();
    let region = state.lock().unwrap().create_root_region(Budget::INFINITE);

    let num_workers = 4;
    let cancel_limit = 8;
    let mut scheduler =
        ThreeLaneScheduler::new_with_cancel_limit(num_workers, &state, cancel_limit);

    let num_per_lane = 50;
    let mut cancel_ids = Vec::new();
    let mut timed_ids = Vec::new();
    let mut ready_ids = Vec::new();

    for _ in 0..num_per_lane {
        let c = create_task(&state, region);
        let t = create_task(&state, region);
        let r = create_task(&state, region);
        scheduler.inject_cancel(c, 100);
        scheduler.inject_timed(t, Time::ZERO); // Already due.
        scheduler.inject_ready(r, 100);
        cancel_ids.push(c);
        timed_ids.push(t);
        ready_ids.push(r);
    }

    let workers = scheduler.take_workers();
    let handles: Vec<_> = workers
        .into_iter()
        .map(|mut w| {
            std::thread::spawn(move || {
                w.run_loop();
            })
        })
        .collect();

    std::thread::sleep(Duration::from_secs(1));
    scheduler.shutdown();
    for h in handles {
        h.join().unwrap();
    }

    let guard = state.lock().unwrap();
    let cancel_done = cancel_ids
        .iter()
        .filter(|id| guard.task(**id).is_none())
        .count();
    let timed_done = timed_ids
        .iter()
        .filter(|id| guard.task(**id).is_none())
        .count();
    let ready_done = ready_ids
        .iter()
        .filter(|id| guard.task(**id).is_none())
        .count();

    assert_eq!(
        cancel_done, num_per_lane,
        "cancel: {cancel_done}/{num_per_lane}"
    );
    assert_eq!(
        timed_done, num_per_lane,
        "timed: {timed_done}/{num_per_lane}"
    );
    assert_eq!(
        ready_done, num_per_lane,
        "ready: {ready_done}/{num_per_lane}"
    );
}

// ===========================================================================
// STRESS: LARGE CANCEL CASCADE WITH MULTIPLE READY TASKS
// ===========================================================================

#[test]
fn stress_large_cancel_cascade_multiple_ready_tasks() {
    init_test_logging();
    let state = setup_state();
    let region = state.lock().unwrap().create_root_region(Budget::INFINITE);

    let cancel_limit = 16;
    let mut scheduler = ThreeLaneScheduler::new_with_cancel_limit(1, &state, cancel_limit);

    // 1000 cancel tasks.
    for _ in 0..1000 {
        let id = create_task(&state, region);
        scheduler.inject_cancel(id, 100);
    }

    // 10 ready tasks interspersed.
    let mut ready_ids = Vec::new();
    for _ in 0..10 {
        let id = create_task(&state, region);
        scheduler.inject_ready(id, 100);
        ready_ids.push(id);
    }

    let workers = scheduler.take_workers();
    let mut worker = workers.into_iter().next().unwrap();
    let handle = std::thread::spawn(move || {
        worker.run_loop();
    });

    std::thread::sleep(Duration::from_secs(2));
    scheduler.shutdown();
    handle.join().unwrap();

    let guard = state.lock().unwrap();
    let ready_done = ready_ids
        .iter()
        .filter(|id| guard.task(**id).is_none())
        .count();
    assert_eq!(
        ready_done,
        ready_ids.len(),
        "all ready tasks should complete despite 1000 cancel tasks"
    );
}

// ===========================================================================
// BOUND WITH MIXED TIMED AND READY AGAINST CANCEL FLOOD
// ===========================================================================

#[test]
fn mixed_timed_ready_not_starved_by_cancel() {
    init_test_logging();
    let (state, _clock) = setup_state_with_clock();
    let region = state.lock().unwrap().create_root_region(Budget::INFINITE);

    let cancel_limit = 4;
    let mut scheduler = ThreeLaneScheduler::new_with_cancel_limit(1, &state, cancel_limit);

    // 50 cancel tasks.
    for _ in 0..50 {
        let id = create_task(&state, region);
        scheduler.inject_cancel(id, 100);
    }

    // 1 timed task (due now) + 1 ready task.
    let timed_id = create_task(&state, region);
    let ready_id = create_task(&state, region);
    scheduler.inject_timed(timed_id, Time::ZERO);
    scheduler.inject_ready(ready_id, 100);

    let workers = scheduler.take_workers();
    let mut worker = workers.into_iter().next().unwrap();
    let handle = std::thread::spawn(move || {
        worker.run_loop();
    });

    std::thread::sleep(Duration::from_millis(300));
    scheduler.shutdown();
    handle.join().unwrap();

    let (timed_done, ready_done) = {
        let guard = state.lock().unwrap();
        (
            guard.task(timed_id).is_none(),
            guard.task(ready_id).is_none(),
        )
    };
    assert!(
        timed_done,
        "timed task should complete despite cancel flood"
    );
    assert!(
        ready_done,
        "ready task should complete despite cancel flood"
    );
}

// ===========================================================================
// DETERMINISTIC DISPATCH ORDER WITH FIXED SEED
// ===========================================================================

fn dispatch_sequence(cancel_limit: usize) -> Vec<TaskId> {
    let state = setup_state();
    let mut scheduler = ThreeLaneScheduler::new_with_cancel_limit(1, &state, cancel_limit);

    let c1 = TaskId::new_for_test(1, 0);
    let c2 = TaskId::new_for_test(1, 1);
    let c3 = TaskId::new_for_test(1, 2);
    let r1 = TaskId::new_for_test(2, 0);

    scheduler.inject_cancel(c1, 10);
    scheduler.inject_cancel(c2, 10);
    scheduler.inject_cancel(c3, 10);
    scheduler.inject_ready(r1, 10);

    let workers = scheduler.take_workers();
    let mut worker = workers.into_iter().next().unwrap();
    let mut order = Vec::new();

    for _ in 0..10 {
        match worker.next_task() {
            Some(task_id) => order.push(task_id),
            None => break,
        }
    }

    order
}

#[test]
fn deterministic_dispatch_order_with_fixed_limit() {
    init_test_logging();

    // With limit=2: should be cancel, cancel, ready, cancel.
    let seq = dispatch_sequence(2);
    let seq_len = seq.len();
    assert!(
        seq_len >= 4,
        "expected at least 4 dispatches, got {seq_len}"
    );

    let ready_task = TaskId::new_for_test(2, 0);
    let ready_idx = seq
        .iter()
        .position(|t| t == &ready_task)
        .expect("ready task should be in dispatch sequence");
    assert!(
        ready_idx <= 2,
        "with limit=2, ready should dispatch at position <=2, got {ready_idx}"
    );

    // Repeated runs should produce the same order (determinism).
    let seq2 = dispatch_sequence(2);
    assert_eq!(seq, seq2, "dispatch order should be deterministic");
}
